{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarelaj/nlp-miniproyecto-icesi/blob/main/analisis_sentimientos_quejas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ANÁLISIS DE SENTIMIENTO EN QUEJAS DE SOPORTE TÉCNICO (ARL)\n",
        "**Autores:** Diana Varela, Daniel García, Farid Sandoval  \n",
        "**Programa:** Maestría en Inteligencia Artificial Aplicada - Universidad ICESI  \n",
        "\n",
        "---\n",
        "\n",
        "## CONTEXTO DEL PROYECTO\n",
        "En esta actividad, se busca replicar el flujo de trabajo del notebook de reseñas de películas, pero aplicado a un dominio específico y complejo: **quejas técnicas de una ARL en español**.\n",
        "\n",
        "A diferencia del ejemplo base, aquí enfrentamos dos retos adicionales:\n",
        "* **Cambio de Idioma:** Se migra de VADER (inglés) a `pysentimiento`, un modelo basado en Deep Learning (BERT) optimizado para español.\n",
        "* **Dominio Técnico:** El lenguaje corporativo y técnico presenta matices de neutralidad y negatividad que difieren del lenguaje coloquial de las películas."
      ],
      "metadata": {
        "id": "P8j1BQx6WBVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter\n",
        "import spacy.cli\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "0Q1bid9ayu92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se hace etiquetado manual sobre la muestra de quejas seleccionadas para correr el modelo y poder comparar."
      ],
      "metadata": {
        "id": "9r-6BLW5_X6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de GitHub\n",
        "url_datos = 'https://raw.githubusercontent.com/dvarelaj/nlp-miniproyecto-icesi/main/quejas_anonimizadas_muestra_etiqueta.csv'\n",
        "df = pd.read_csv(url_datos, delimiter=';')"
      ],
      "metadata": {
        "id": "hhGkN1SIyvZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. PRE-PROCESAMIENTO\n",
        "Para garantizar la calidad de las predicciones, realizamos un flujo de limpieza.\n",
        "\n",
        "* **Carga de datos:** Se utiliza una muestra de **101 registros** anonimizados de la ARL.\n",
        "* **Limpieza:** Se eliminan valores nulos y celdas con espacios en blanco en la descripción de la queja para evitar errores en el tokenizador."
      ],
      "metadata": {
        "id": "9YRFfP30zlpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza básica\n",
        "df.dropna(subset=['descripcion_anonimizada'], inplace=True)\n",
        "df = df[df['descripcion_anonimizada'].str.strip() != '']\n",
        "\n",
        "print(f\"Total de quejas para analizar: {len(df)}\")"
      ],
      "metadata": {
        "id": "s37ZnuJezP-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. IMPLEMENTACIÓN DEL MODELO\n",
        "A diferencia del modelo basado en léxicos (VADER) visto en clase, para este caso \"personalizado\" optamos por un **Sentiment Analyzer** basado en Transformers, ya que nuestro archivo de datos tiene quejas y peticiones en español.\n",
        "\n",
        "Este modelo es superior para el español ya que:\n",
        "1. Entiende el contexto bidireccional de las frases.\n",
        "2. Detecta ironía y matices técnicos que modelos más simples ignorarían."
      ],
      "metadata": {
        "id": "wKN_dE66z_iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pysentimiento"
      ],
      "metadata": {
        "id": "8QTl5Stn0hM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysentimiento\n",
        "import pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "# Aplicamos el análisis a nuestras quejas\n",
        "df['sentiment_results'] = df['descripcion_anonimizada'].apply(lambda x: analyzer.predict(x))\n",
        "df['prediction'] = df['sentiment_results'].apply(lambda r: r.output)\n",
        "df['compound_score'] = df['sentiment_results'].apply(lambda r: r.probas['NEG'] * -1 if r.output == 'NEG' else r.probas['POS'])\n",
        "\n",
        "df[['descripcion_anonimizada', 'prediction']].head()"
      ],
      "metadata": {
        "id": "oNvT0OG90ww_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteo de los resultados obtenidos por el modelo\n",
        "conteo_sentimientos = df['prediction'].value_counts()\n",
        "print(conteo_sentimientos)"
      ],
      "metadata": {
        "id": "CQ1EMFIG1gxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones del modelo\n",
        "y_pred = [p.lower() for p in df['prediction'].tolist()]\n",
        "\n",
        "# Obtener las etiquetas verdaderas\n",
        "y_true = df['y_true'].tolist()\n",
        "\n",
        "# Generar el reporte (requires y_true)\n",
        "reporte = classification_report(y_true, y_pred)\n",
        "print(\"### Reporte de Clasificación ###\")\n",
        "print(reporte)\n",
        "\n",
        "# Calcular exactitud total (requires y_true)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy Total: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Yx5GBfs29PJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la matriz de confusión\n",
        "labels = ['neg', 'neu', 'pos']\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción del Modelo (pysentimiento)')\n",
        "plt.ylabel('Etiqueta Real (Manual)')\n",
        "plt.title('Matriz de Confusión: Quejas ARL')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EWkothjZ-r-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ANÁLISIS DE RESULTADOS\n",
        "\n",
        "Una vez ejecutado el modelo sobre las 101 quejas, se presentan los siguientes hallazgos críticos basados en las métricas obtenidas:\n",
        "\n",
        "### A. RENDIMIENTO DEL MODELO\n",
        "El modelo supera significativamente la línea base del 50%, logrando un **Accuracy del 71%**. Sin embargo, el rendimiento es asimétrico:\n",
        "* **Alta Precisión en Negativos (0.86):** El modelo es muy efectivo detectando la molestia real del usuario en temas de fallas técnicas.\n",
        "* **Debilidad en Neutrales (Precision 0.37):** Existe una confusión importante entre quejas informativas y consultas de trámites.\n",
        "\n",
        "\n",
        "\n",
        "### B. OBSERVACIONES LINGÜÍSTICAS\n",
        "Como hallazgo, identificamos un fenómeno de **\"Ambigüedad de Dominio\"**:\n",
        "* Términos como *\"mantenimiento\"*, *\"portal no carga\"* o *\"no permite ingresar\"* son clasificados frecuentemente como **NEG** (negativos) por el modelo.\n",
        "* Lingüísticamente, estas frases podrían ser informativas (Neutrales), pero en el ecosistema de una ARL, el modelo interpreta correctamente la carga emocional de frustración implícita en la imposibilidad de realizar una tarea.\n",
        "\n",
        "### C. COMPARACIÓN CON EL MODELO BASE\n",
        "* **Desbalance Natural:** A diferencia del dataset de películas (balanceado 50/50), las quejas de la ARL están **naturalmente desbalanceadas hacia lo negativo**.\n",
        "* **Ausencia de Positivos:** La ausencia total de sentimientos positivos (**POS = 0**) refleja la realidad de los canales de soporte: el usuario rara vez se comunica para expresar satisfacción en un canal de reclamos."
      ],
      "metadata": {
        "id": "c8Hs18YT_45P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de barras para visualizar el desbalance de sentimientos\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.countplot(x='prediction', data=df, palette='viridis')\n",
        "plt.title('Distribución de Predicciones: Dominio ARL')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qztM9gWidSTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}