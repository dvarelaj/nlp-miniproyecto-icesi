{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2b2362P5cx03J+89UlTHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvarelaj/nlp-miniproyecto-icesi/blob/main/analisis_sentimientos_quejas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from spacy.matcher import Matcher\n",
        "from collections import Counter\n",
        "import spacy.cli\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "0Q1bid9ayu92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se hace etiquetado manual sobre la muestra de quejas seleccionadas para correr el modelo y poder comparar."
      ],
      "metadata": {
        "id": "9r-6BLW5_X6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de GitHub\n",
        "url_datos = 'https://raw.githubusercontent.com/dvarelaj/nlp-miniproyecto-icesi/main/quejas_anonimizadas_muestra_etiqueta.csv'\n",
        "df = pd.read_csv(url_datos, delimiter=';')"
      ],
      "metadata": {
        "id": "hhGkN1SIyvZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, hagamos algo de limpieza, vamos a remover nulos y valores vacíos:"
      ],
      "metadata": {
        "id": "9YRFfP30zlpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza básica\n",
        "df.dropna(subset=['descripcion_anonimizada'], inplace=True)\n",
        "df = df[df['descripcion_anonimizada'].str.strip() != '']\n",
        "\n",
        "print(f\"Total de quejas para analizar: {len(df)}\")"
      ],
      "metadata": {
        "id": "s37ZnuJezP-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En lugar de nltk.vader, usaremos un analizador profesional para español ya que nuestro archivo de datos tiene quejas y peticiones en español."
      ],
      "metadata": {
        "id": "wKN_dE66z_iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pysentimiento"
      ],
      "metadata": {
        "id": "8QTl5Stn0hM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pysentimiento import create_analyzer\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "# Aplicamos el análisis a nuestras quejas\n",
        "df['sentiment_results'] = df['descripcion_anonimizada'].apply(lambda x: analyzer.predict(x))\n",
        "df['prediction'] = df['sentiment_results'].apply(lambda r: r.output)\n",
        "df['compound_score'] = df['sentiment_results'].apply(lambda r: r.probas['NEG'] * -1 if r.output == 'NEG' else r.probas['POS'])\n",
        "\n",
        "df[['descripcion_anonimizada', 'prediction']].head()"
      ],
      "metadata": {
        "id": "oNvT0OG90ww_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteo de los resultados obtenidos por el modelo\n",
        "conteo_sentimientos = df['prediction'].value_counts()\n",
        "print(conteo_sentimientos)"
      ],
      "metadata": {
        "id": "CQ1EMFIG1gxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones del modelo\n",
        "y_pred = [p.lower() for p in df['prediction'].tolist()]\n",
        "\n",
        "# Obtener las etiquetas verdaderas\n",
        "y_true = df['y_true'].tolist()\n",
        "\n",
        "# Generar el reporte (requires y_true)\n",
        "reporte = classification_report(y_true, y_pred)\n",
        "print(\"### Reporte de Clasificación ###\")\n",
        "print(reporte)\n",
        "\n",
        "# Calcular exactitud total (requires y_true)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy Total: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Yx5GBfs29PJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REVISAR\n",
        "Interpretación de Métricas:\n",
        "\n",
        "Sesgo hacia Negativo: Se observa que el modelo tiene un alto Recall para la clase neg, identificando casi todas las quejas de falla técnica.\n",
        "\n",
        "Confusión en Neutrales: Existe una tendencia del modelo a clasificar casos neu (consultas de mantenimiento o trámites) como neg. Esto ocurre porque palabras como \"mantenimiento\" o \"no carga\" tienen una carga semántica negativa para el modelo, aunque el usuario esté informando una situación técnica sin molestia explícita.\n",
        "\n",
        "Desbalance: Al ser un corpus de quejas reales, la ausencia de la clase pos dificulta la evaluación de esa categoría, lo cual es un comportamiento esperado en entornos de soporte técnico de una ARL."
      ],
      "metadata": {
        "id": "c8Hs18YT_45P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la matriz de confusión\n",
        "labels = ['neg', 'neu', 'pos']\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción del Modelo (pysentimiento)')\n",
        "plt.ylabel('Etiqueta Real (Manual)')\n",
        "plt.title('Matriz de Confusión: Quejas ARL')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EWkothjZ-r-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}